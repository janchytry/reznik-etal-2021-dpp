{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom modules\n",
    "from aoi import Project, AOI, Patcher\n",
    "from eolearn_datafill import S2L2AImages, CustomInput, AddMask, DerivateProduct, MaskValidation, EstimatorParser\n",
    "# Scikit-learn + LightGBM\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "# eo-learn + sentinelhub\n",
    "from eolearn.core import EOTask, EOPatch, EOExecutor, LinearWorkflow, FeatureType, OverwritePermission, SaveTask, MergeFeatureTask\n",
    "from eolearn.features import LinearInterpolation, SimpleFilterTask, PredictPatch\n",
    "from eolearn.geometry import VectorToRaster, PointSamplingTask, ErosionTask\n",
    "from eolearn.io import ExportToTiff\n",
    "from sentinelhub import CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = Project('jihozapad_brna')\n",
    "\n",
    "# Choose study area: must be a geojson or a shapefile of\n",
    "#a single feautre, which is a polygon of AOI.\n",
    "aoi = AOI('basedata/jmk_aoi.geojson', crs=CRS.UTM_33N)\n",
    "aoi.convert_desired_CRS()\n",
    "\n",
    "# Splitting the area of interest.\n",
    "patcher = Patcher(project)\n",
    "patcher.get_xy_splitters(aoi.dimensions, patch_factor=1)\n",
    "patcher.split_bboxes(aoi.shape)\n",
    "\n",
    "# Create a GeoDataFrame of patches made according to the splitters and central patch selection.\n",
    "# Initial patch can be selected by subset_patch.\n",
    "patcher.get_patch_gdf(subset_patch=54, save=False)\n",
    "patcher.get_patch_map(aoi.gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing cadastre reference map\n",
    "# Loading this file takes around 3 minutes\n",
    "LC = gpd.read_file('cadastre_south_moravian_region.shp')\n",
    "# Copying dataset for modifications\n",
    "land_cover = LC.copy()\n",
    "# Reclassifying the information classes\n",
    "reclassify = {\n",
    "    2: 1,\n",
    "    3: 0,\n",
    "    4: 2,\n",
    "    5: 3,\n",
    "    6: 4,\n",
    "    7: 5,\n",
    "    10: 6,\n",
    "    11: 7,\n",
    "    13: 8,\n",
    "    14: 0,\n",
    "}\n",
    "\n",
    "land_cover['druh_pozem'] = land_cover['druh_pozem'].map(reclassify) # Note: druh_pozem = lulc type on the estate\n",
    "# Masking invalid geometries from the cadastre dataset\n",
    "mask = (land_cover['geometry']!='shapely.geometry.polygon.Polygon')\n",
    "land_cover = land_cover[mask]\n",
    "# Adding roads to built-up areas\n",
    "land_cover.loc[land_cover.zpusob_vyu.isin([15,16,18]), 'druh_pozem'] = 8\n",
    "# Removing class 0: no-data/other surfaces\n",
    "land_cover = land_cover[land_cover['druh_pozem']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining available Sentinel-2 L2A images and retrieving their metadata\n",
    "images = S2L2AImages(patcher.gdf, project.FOLDER)\n",
    "images.get_patches_bbox()\n",
    "\n",
    "images.get_available(\n",
    "    esa_sci_hub_credentials = ('username', 'password'), # Credentials to Copernicus Open Access Hub must be supplied\n",
    "    date_range=('20190301', '20191130'), # Download range\n",
    "    cloudcov=(0, 60) # Cloud coverage restriction\n",
    ") \n",
    "\n",
    "# The possibility to select concrete images from the range\n",
    "images.select() # No arguments means download all available\n",
    "# Download images\n",
    "images.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desining the workflow to amend and process Sentinel-2, cadastre data\n",
    "# and to almost prepare them for the classification\n",
    "# Custom EOTask for adding and parsing downloaded images.\n",
    "customS2L2A = CustomInput(\n",
    "    images_gdf=images.downloaded, # Downloaded images dataframe\n",
    "    path_to_images=project.FOLDER, # Path to downloaded images\n",
    "    custom_input_name='BANDS' # Key name of input data in EOPatches\n",
    ") \n",
    "\n",
    "# Custom EOTask for adding a mask from Sentinel-2 L2A 20m Scene Classification Layer (SCL)\n",
    "# that is clipped and resampled to 10 m\n",
    "addmask = AddMask(\n",
    "    images_gdf=images.downloaded,\n",
    "    path_to_images=project.FOLDER,\n",
    "    mask_name='SCL_MASK'\n",
    ")\n",
    "\n",
    "# Original eo-learn EOTask for rasterizing cadastre LULC map\n",
    "# and adding it to FeatureType.mask_timeless['LULC']\n",
    "lulc_rasterization = VectorToRaster(\n",
    "    land_cover, # Land cover GeoDataFrame\n",
    "    (FeatureType.MASK_TIMELESS, 'LULC'), # FeatureType and name of the feature to save to EOPatches\n",
    "    values_column='druh_pozem', # GeoDataFrame column to be used as a raster value\n",
    "    raster_shape=(FeatureType.MASK, 'SCL_MASK'), # Make land cover to have same dimensions and cell size as SCL MASK\n",
    "    raster_dtype=np.dtype(np.uint8) # NumPy array data type = unsigned 8 bit integer (meaningful for cadastre data)\n",
    ")\n",
    "\n",
    "# Original eo-learn EOTask for merging data along the band dimension\n",
    "merging = MergeFeatureTask(\n",
    "    {FeatureType.DATA: ['BANDS', 'NDVI']}, # Features to merge\n",
    "    (FeatureType.DATA, 'FEATURES') # FeatureType and name of the feature to save to EOPatches\n",
    ")\n",
    "\n",
    "# Validation, according to the SCL mask\n",
    "valid_data = MaskValidation(0.1) # Maximum threshold (10 %) of False pixels\n",
    "# Original eo-learn for filtering images according to the MaskValidation\n",
    "filtering = SimpleFilterTask(\n",
    "    (FeatureType.MASK, 'SCL_MASK'), # FeatureType and name of the feature to save to EOPatches\n",
    "    valid_data # CLMValidation results\n",
    ")\n",
    "\n",
    "# Original eo-learn for merging data along the band dimension\n",
    "interpolation = LinearInterpolation(\n",
    "    'FEATURES', # FeatureType data to be interpolated\n",
    "    copy_features=[\n",
    "        (FeatureType.MASK_TIMELESS, 'LULC'),\n",
    "        (FeatureType.META_INFO)\n",
    "    ], # Preserving some features in EOPatches\n",
    "    mask_feature=(FeatureType.MASK, 'SCL_MASK'), # Masking data with the respective CLMs\n",
    "    resample_range=(\n",
    "        '2019-03-30', # First date of arbitrary range\n",
    "        '2019-10-18', # Last date of arbitrary range\n",
    "        10 # Interpolation step in days\n",
    "    )\n",
    ")\n",
    "\n",
    "# Sampling pixels from patches for the estimator\n",
    "spatial_sampling = PointSamplingTask(\n",
    "    n_samples=50000, # Number of pixels to sample from each band in each time frame in each EOPatch\n",
    "    ref_mask_feature='LULC', # Reference map (e.g. cadastre reference map)\n",
    "    ref_labels=list(range(1,9)), # Unique information class labels from the reference map\n",
    "    sample_features=[ # Specify which fields to sample\n",
    "        (FeatureType.DATA, 'FEATURES'),\n",
    "        (FeatureType.MASK_TIMELESS, 'LULC')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Custom EOTask for removing no-date (Nans) from sampled pixels\n",
    "nrm = NanRemover(\n",
    "    sampled_feature_name='FEATURES',\n",
    "    sampled_lulc_name='LULC_SAMPLED'\n",
    ")\n",
    "\n",
    "# Original eo-learn EOTask for saving EOPatches as npy files to disk\n",
    "save = SaveTask(project.FOLDER, overwrite_permission=OverwritePermission.OVERWRITE_PATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Instantiating EOWorkflow\n",
    "workflow = LinearWorkflow(\n",
    "    customS2L2A,\n",
    "    addmask,\n",
    "    ndvi,\n",
    "    ndwi,\n",
    "    ndbi,\n",
    "    lulc_rasterization,\n",
    "    merging,\n",
    "    filtering,\n",
    "    interpolation,\n",
    "    lulc_erosion,\n",
    "    spatial_sampling,\n",
    "    nrm,\n",
    "    save\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External parameters of the workflow\n",
    "execution_args = patcher.gdf.apply(\n",
    "    lambda row: {\n",
    "        customS2L2A: {'patch_bbox': row[3]}, # row[3] = Patcher DataFrame position of bounding box column\n",
    "        addmask: {'patch_bbox': row[3]},\n",
    "        save: {'eopatch_folder': f'eopatch{row[2]}'} # row[2] = Patcher DataFrame position of bounding box ID column\n",
    "    }, \n",
    "    axis=1).to_list()\n",
    "\n",
    "# Instantiating EOExecutor\n",
    "executor = EOExecutor(\n",
    "    workflow, # The workflow defined above\n",
    "    execution_args, # External execution arguments to feed to EOTasks\n",
    "    save_logs=True, # Save detailed logs about what is happening\n",
    "    logs_folder=project.FOLDER\n",
    ")\n",
    "\n",
    "# Running the workflow\n",
    "executor.run(workers=9) # Specify multiprocessing division to CPU threads\n",
    "executor.make_report() # Make an HTML report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Loading EOPatches and feeding them to EstimatorParser class to get\n",
    "# the feature vectors and information class labels\n",
    "eopatches = np.array([EOPatch.load(os.path.join(project.FOLDER, f'eopatch{i}'), lazy_loading=True) for i in range(9)])\n",
    "\n",
    "# Reducing feature space of training data\n",
    "parse_training_data = EstimatorParser(\n",
    "    eopatches, # Feed EOPatches\n",
    "    patch_ids=[7,3,5,8,0], # Which EOPatches\n",
    "    features='FEATURES_SAMPLED', # Which features to reduce\n",
    "    classes='LULC_SAMPLED' # LULC to reduce\n",
    ") \n",
    "\n",
    "# Reducing feature space of testing data\n",
    "parse_testing_data = EstimatorParser(\n",
    "    eopatches,\n",
    "    patch_ids=[6,1,2,4],\n",
    "    features='FEATURES_SAMPLED',\n",
    "    classes='LULC_SAMPLED'\n",
    ")\n",
    "\n",
    "train_features, train_classes = parse_training_data()\n",
    "test_features, test_classes = parse_testing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Adapted from Lubej (2019a, 2019b), eo-learn (2018)\n",
    "#Set up training classes\n",
    "labels_unique = np.unique(train_classes)\n",
    "\n",
    "# LightGBM model with default parametres\n",
    "model = lgb.LGBMClassifier(\n",
    "    objective='multiclassova',\n",
    "    num_class=len(labels_unique),\n",
    "    metric='multi_logloss',\n",
    "    random_state = 10\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_features, train_classes)\n",
    "\n",
    "# Testing the trained model on test features\n",
    "prediction_test_set = model.predict(features_test)\n",
    "\n",
    "# Obtaining pixel confusion matrix from predicted test samples and\n",
    "# corresponding (but ground truth) test classes\n",
    "confusion_matrix = metrics.confusion_matrix(prediction_test_set, test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showcase of predicting an EOPatch\n",
    "predict = PredictPatch(model, feature_name='PREDICTED_LULC')\n",
    "eopatch_predicted = PredictPatch.execute(eopatch)\n",
    "\n",
    "# Original EOTask for exporting predicted LULC to GEoTiff\n",
    "export_tiff = ExportToTiff(\n",
    "    (FeatureType.MASK_TIMELESS, 'PREDICTED_LULC'), \n",
    "    filename='predicted_eopatch1.tiff'\n",
    ")\n",
    "\n",
    "export_tiff.execute(eopatch_predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
